{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State: 1-D array of image + coordinates of previous bbox\n",
    "Action: Left, Right, None\n",
    "\n",
    "In this second phase, we pass a 1-D array of the image, in which one cell indicates the position of the object. Along with this, we include the one-hot vector of the previous bounding box in the state. \n",
    "\n",
    "Thus, we have a very simple network of this form:\n",
    "\n",
    "\n",
    "       i1             \n",
    "                 h11         h21        left_prob\n",
    "       i2       \n",
    "                 h12         h22   \n",
    "       ..       \n",
    "                 h13         h23        none_prob\n",
    "       i10       \n",
    "       \n",
    "       p1        ...         ...\n",
    "       \n",
    "       p2                               right_prob\n",
    "       \n",
    "       ..        h110        h210\n",
    "       \n",
    "       p10\n",
    "       \n",
    "\n",
    "We have a neural network consisting of only fully connected layers of dimension 20 x 10 x 10 x 3. Here, we have 20 input units (corresponding to the board state and the previous bbox one-hot vector), 10 units in the first hidden layer, 10 units in the second hidden layer, and 3 units \n",
    "\n",
    "The outputs consist of the probabilities of going right, left and staying at the same position. The action then gives the direction in which this previous bounding box should move in order to coincide with the current actual bounding box.\n",
    "\n",
    "This method trains on trajectories for which labels for only the first and the last frame are provided. After each episode terminates, the reward is given by the negative of the L-1 distance between the bounding box and the actual object position. For all intermediate steps, which do not have a label associated with them, the reward is set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_positions = 10\n",
    "input_size = 20 # [board configuration:10, one-hot previous bbox vector:10]\n",
    "hidden_layer_1_size = 10\n",
    "hidden_layer_2_size = 10\n",
    "output_size = 3 # number of actions = 3 : Left, None, Right\n",
    "num_actions = 3\n",
    "gamma = 0.9\n",
    "alpha = 0.01\n",
    "epsilon = 0.2\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder('float', [None, input_size])\n",
    "\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([input_size, hidden_layer_1_size])),\n",
    "    'h2': tf.Variable(tf.random_normal([hidden_layer_1_size, hidden_layer_2_size])),\n",
    "    'out': tf.Variable(tf.random_normal([hidden_layer_2_size, output_size]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([hidden_layer_1_size])),\n",
    "    'b2': tf.Variable(tf.random_normal([hidden_layer_2_size])),\n",
    "    'out': tf.Variable(tf.random_normal([output_size]))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(x):\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['h1']), biases['b1']))\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['h2']), biases['b2']))\n",
    "    out_layer = tf.nn.softmax(tf.matmul(layer_2, weights['out']) + biases['out'])\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = network(X)\n",
    "actual_return = tf.Variable([[0.0, 0.0, 0.0]], name='actual_return', dtype=tf.float32, validate_shape=False)\n",
    "expected_return = tf.placeholder('float', [None, 3], name='expected_return')\n",
    "loss = tf.reduce_mean(tf.square(tf.subtract(actual_return, expected_return)))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=alpha)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate 100000 trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_trajectories = []\n",
    "\n",
    "for i in xrange(100000):\n",
    "    obj_start = np.random.randint(0, num_positions)\n",
    "    obj_start = [0 if x != obj_start else 1 for x in xrange(num_positions)]\n",
    "    obj = obj_start\n",
    "    trajectory = [obj]\n",
    "    for j in xrange(10):\n",
    "        a = np.random.randint(0, num_actions)\n",
    "        obj_coord = obj.index(1)\n",
    "        while (obj_coord == 0 and a == 0) or (obj_coord == num_positions - 1 and a == 2):\n",
    "            a = np.random.randint(0, num_actions)\n",
    "        obj_coord = obj_coord - 1 if a == 0 else obj_coord if a == 1 else obj_coord + 1\n",
    "        obj = [0 if x != obj_coord else 1 for x in xrange(num_positions)]\n",
    "        trajectory.append(obj)\n",
    "    training_trajectories.append(trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy(actions):\n",
    "    if np.random.rand() <= epsilon:\n",
    "        return np.argmax(actions)\n",
    "    return np.random.randint(0, len(actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-bf97ec7c3bd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0;31m# Otherwise, we add the new state and action to their respective arrays.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcurrent_box_coord\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcurrent_box_coord\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mnum_positions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_return\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10.0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcurrent_action\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mexpected_return\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aditi/.local/lib/python2.7/site-packages/tensorflow/python/ops/state_ops.pyc\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m    274\u001b[0m     return gen_state_ops.assign(\n\u001b[1;32m    275\u001b[0m         \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         validate_shape=validate_shape)\n\u001b[0m\u001b[1;32m    277\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aditi/.local/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.pyc\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m     58\u001b[0m         \u001b[0;34m\"Assign\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         use_locking=use_locking, name=name)\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aditi/.local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    508\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    511\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aditi/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aditi/.local/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.pyc\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    231\u001b[0m                                          as_ref=False):\n\u001b[1;32m    232\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aditi/.local/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.pyc\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    216\u001b[0m       attrs={\"value\": tensor_value,\n\u001b[1;32m    217\u001b[0m              \"dtype\": dtype_value},\n\u001b[0;32m--> 218\u001b[0;31m       name=name).outputs[0]\n\u001b[0m\u001b[1;32m    219\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconst_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aditi/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3158\u001b[0m         \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3159\u001b[0m         \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3160\u001b[0;31m         op_def=op_def)\n\u001b[0m\u001b[1;32m   3161\u001b[0m     self._create_op_helper(ret, compute_shapes=compute_shapes,\n\u001b[1;32m   3162\u001b[0m                            compute_device=compute_device)\n",
      "\u001b[0;32m/home/aditi/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1664\u001b[0m     self._outputs = [\n\u001b[1;32m   1665\u001b[0m         \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1666\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1667\u001b[0m     ]\n\u001b[1;32m   1668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aditi/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, op, value_index, dtype)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munknown_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;31m# List of operations that use this Tensor as input.  We maintain this list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for k in xrange(num_epochs):\n",
    "        for i in xrange(len(training_trajectories)):\n",
    "            j = 1\n",
    "            prev_box = training_trajectories[i][0]\n",
    "            \n",
    "            states = []\n",
    "            actions = []\n",
    "            actual_returns = []\n",
    "            expected_returns = []\n",
    "            \n",
    "            # Evaluate the Q-network to get the Q-values, and on the basis of that, select an action, and\n",
    "            # consequently calculate the current box coordinates from the action on the previous box coordinates\n",
    "            while j < len(training_trajectories[i]):\n",
    "                current_state = training_trajectories[i][j] + prev_box\n",
    "                current_qvalues = sess.run([output], feed_dict={X:[current_state]})[0][0]\n",
    "                current_action = epsilon_greedy(current_qvalues)\n",
    "                prev_box_coord = prev_box.index(1)\n",
    "                current_box_coord = prev_box_coord - 1 if current_action == 0 else prev_box_coord if current_action == 1 else prev_box_coord + 1\n",
    "                current_box = [0 if x != current_box_coord else 1 for x in xrange(num_positions)]\n",
    "                \n",
    "                # If the current box coordinates are invalid (out of bounds), we set a penalty for them and backpropagate.\n",
    "                # Otherwise, we add the new state and action to their respective arrays.\n",
    "                if current_box_coord < 0 or current_box_coord >= num_positions:\n",
    "                    sess.run(tf.assign(actual_return, [10.0 if x == current_action else 0.0 for x in xrange(num_actions)], validate_shape=False))\n",
    "                    sess.run([train_op], feed_dict={expected_return:[[0.0 for x in xrange(num_actions)]]})\n",
    "                    j = 1\n",
    "                    states = []\n",
    "                    actions = []\n",
    "                    actual_returns = []\n",
    "                    prev_box = training_trajectories[i][0]\n",
    "                else:\n",
    "                    states.append(current_state)\n",
    "                    actions.append(current_action)\n",
    "                    actual_returns.append([current_qvalues[x] if x == current_action else 0.0 for x in xrange(num_actions)])\n",
    "                    prev_box = current_box\n",
    "                    j += 1\n",
    "                    \n",
    "            # Assign rewards. Here, the reward is 0 if the end point is the same as the starting point and\n",
    "            # -distance between the final actual and predicted bounding boxes. The reward is 0 for all intermediate steps.\n",
    "            rewards = np.zeros(len(training_trajectories[i]) - 1, dtype=np.float32)\n",
    "            rewards[-1] = -abs(1.0 * current_box_coord - training_trajectories[i][-1].index(1))\n",
    "            prev_box = training_trajectories[i][0]\n",
    "            \n",
    "            for j in xrange(len(training_trajectories[i]) - 2, -1, -1):\n",
    "                current_state = states[j]\n",
    "                current_action = actions[j]\n",
    "                prev_box = current_state[num_positions:]\n",
    "                prev_box_coord = prev_box.index(1)\n",
    "                current_box_coord = prev_box_coord - 1 if current_action == 0 else prev_box_coord if current_action == 1 else prev_box_coord + 1\n",
    "                current_box = [0 if x != current_box_coord else 1 for x in xrange(num_positions)]\n",
    "\n",
    "                current_qvalues = actual_returns[j]\n",
    "\n",
    "                next_state = current_state[:num_positions] + current_box\n",
    "                next_qvalues = sess.run(output, feed_dict={X:[next_state]})[0]\n",
    "                max_action = np.argmax(next_qvalues)\n",
    "                \n",
    "                # We will only update weights for the max action chosen for the next state, so all other actions are made to\n",
    "                # have the same output as the previous output for Q-values so that their loss is 0 and thus not updated.\n",
    "                target_qvalues = [rewards[j] + gamma * next_qvalues[x] if x == max_action else current_qvalues[x] for x in xrange(len(next_qvalues))]\n",
    "\n",
    "                expected_returns.append(target_qvalues)\n",
    "                        \n",
    "            # Train!\n",
    "            sess.run(tf.assign(actual_return, actual_returns, validate_shape=False))\n",
    "            sess.run([train_op], feed_dict={expected_return:expected_returns})\n",
    "            \n",
    "            if (i + 1) % 1000 == 0:\n",
    "                print str(i + 1)\n",
    "                saver.save(sess, './qlV.ckpt', global_step=k*len(training_trajectories) + i + 1)\n",
    "            \n",
    "            epsilon = 1/(5+0.01*(k * len(training_trajectories) + i + 1))\n",
    "            \n",
    "        print 'Epoch ' + str(k)\n",
    "        print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
