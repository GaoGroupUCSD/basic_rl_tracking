{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State: 1-D array of image + coordinates of previous bbox\n",
    "Action: Left, Right, None\n",
    "\n",
    "In this second phase, we pass a 1-D array of the image, in which one cell indicates the position of the object. Along with this, we include the coordinates (in this case, just the position along the 1-D array) of the previous bounding box in the state. \n",
    "\n",
    "Thus, we have a very simple network of this form:\n",
    "\n",
    "\n",
    "       i1             \n",
    "                         left_prob\n",
    "       i2       \n",
    "                         none_prob\n",
    "       ..       \n",
    "                         right_prob\n",
    "       i10       \n",
    "       \n",
    "       prev_bbox\n",
    "       \n",
    "Each of the inputs is connected to each of the outputs. The outputs consist of the probabilities of going right, left and staying at the same position. The action then gives the direction in which this previous bounding box should move in order to coincide with the current actual bounding box.\n",
    "\n",
    "This method trains on trajectories for which labels for only the first and the last frame are provided. After each episode terminates, the reward is given by +1 if the final bounding box coincides with the actual bounding box, and -1 otherwise. For all intermediate steps, which do not have a label associated with them, the reward is set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_positions = 10\n",
    "num_actions = 3\n",
    "gamma = 0.9\n",
    "alpha = 0.01\n",
    "epsilon = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#W = np.random.rand(num_positions + 1, num_actions)\n",
    "\n",
    "W = np.load('7000.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 10000 random trajectories and perform Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(s, W):\n",
    "    return 1.0 / (1.0 + np.exp(-1.0 * np.dot(s, W)))\n",
    "\n",
    "def epsilon_greedy(actions):\n",
    "    if np.random.rand() <= epsilon:\n",
    "        return np.argmax(actions)\n",
    "    return np.random.randint(0, len(actions))\n",
    "\n",
    "def backpropagate(gradients):\n",
    "    global W\n",
    "    W = W - alpha * gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7010\n",
      "7020\n",
      "7030\n",
      "7040\n",
      "7050\n",
      "7060\n",
      "7070\n",
      "7080\n",
      "7090\n",
      "7100\n",
      "7110\n",
      "7120\n",
      "7130\n",
      "7140\n",
      "7150\n",
      "7160\n",
      "7170\n",
      "7180\n",
      "7190\n",
      "7200\n",
      "7210\n",
      "7220\n",
      "7230\n",
      "7240\n",
      "7250\n",
      "7260\n",
      "7270\n",
      "7280\n",
      "7290\n",
      "7300\n",
      "7310\n",
      "7320\n",
      "7330\n",
      "7340\n",
      "7350\n",
      "7360\n",
      "7370\n",
      "7380\n",
      "7390\n",
      "7400\n",
      "7410\n",
      "7420\n",
      "7430\n",
      "7440\n",
      "7450\n",
      "7460\n",
      "7470\n",
      "7480\n",
      "7490\n",
      "7500\n",
      "7510\n",
      "7520\n",
      "7530\n",
      "7540\n",
      "7550\n",
      "7560\n",
      "7570\n",
      "7580\n",
      "7590\n",
      "7600\n",
      "7610\n",
      "7620\n",
      "7630\n",
      "7640\n",
      "7650\n",
      "7660\n",
      "7670\n",
      "7680\n",
      "7690\n",
      "7700\n",
      "7710\n",
      "7720\n",
      "7730\n",
      "7740\n",
      "7750\n",
      "7760\n",
      "7770\n",
      "7780\n",
      "7790\n",
      "7800\n",
      "7810\n",
      "7820\n",
      "7830\n",
      "7840\n",
      "7850\n",
      "7860\n",
      "7870\n",
      "7880\n",
      "7890\n",
      "7900\n",
      "7910\n",
      "7920\n",
      "7930\n",
      "7940\n",
      "7950\n",
      "7960\n",
      "7970\n",
      "7980\n",
      "7990\n",
      "8000\n",
      "8010\n",
      "8020\n",
      "8030\n",
      "8040\n",
      "8050\n",
      "8060\n",
      "8070\n",
      "8080\n",
      "8090\n",
      "8100\n",
      "8110\n",
      "8120\n",
      "8130\n",
      "8140\n",
      "8150\n",
      "8160\n",
      "8170\n",
      "8180\n",
      "8190\n",
      "8200\n",
      "8210\n",
      "8220\n",
      "8230\n",
      "8240\n",
      "8250\n",
      "8260\n",
      "8270\n",
      "8280\n",
      "8290\n",
      "8300\n",
      "8310\n",
      "8320\n",
      "8330\n",
      "8340\n",
      "8350\n",
      "8360\n",
      "8370\n",
      "8380\n",
      "8390\n",
      "8400\n",
      "8410\n",
      "8420\n",
      "8430\n",
      "8440\n",
      "8450\n",
      "8460\n",
      "8470\n",
      "8480\n",
      "8490\n",
      "8500\n",
      "8510\n",
      "8520\n",
      "8530\n",
      "8540\n",
      "8550\n",
      "8560\n",
      "8570\n",
      "8580\n",
      "8590\n",
      "8600\n",
      "8610\n",
      "8620\n",
      "8630\n",
      "8640\n",
      "8650\n",
      "8660\n",
      "8670\n",
      "8680\n",
      "8690\n",
      "8700\n",
      "8710\n",
      "8720\n",
      "8730\n",
      "8740\n",
      "8750\n",
      "8760\n",
      "8770\n",
      "8780\n",
      "8790\n",
      "8800\n",
      "8810\n",
      "8820\n",
      "8830\n",
      "8840\n",
      "8850\n",
      "8860\n",
      "8870\n",
      "8880\n",
      "8890\n",
      "8900\n",
      "8910\n",
      "8920\n",
      "8930\n",
      "8940\n",
      "8950\n",
      "8960\n",
      "8970\n",
      "8980\n",
      "8990\n",
      "9000\n",
      "9010\n",
      "9020\n",
      "9030\n",
      "9040\n",
      "9050\n",
      "9060\n",
      "9070\n",
      "9080\n",
      "9090\n",
      "9100\n",
      "9110\n",
      "9120\n",
      "9130\n",
      "9140\n",
      "9150\n",
      "9160\n",
      "9170\n",
      "9180\n",
      "9190\n",
      "9200\n",
      "9210\n",
      "9220\n",
      "9230\n",
      "9240\n",
      "9250\n",
      "9260\n",
      "9270\n",
      "9280\n",
      "9290\n",
      "9300\n",
      "9310\n",
      "9320\n",
      "9330\n",
      "9340\n",
      "9350\n",
      "9360\n",
      "9370\n",
      "9380\n",
      "9390\n",
      "9400\n",
      "9410\n",
      "9420\n",
      "9430\n",
      "9440\n",
      "9450\n",
      "9460\n",
      "9470\n",
      "9480\n",
      "9490\n",
      "9500\n",
      "9510\n",
      "9520\n",
      "9530\n",
      "9540\n",
      "9550\n",
      "9560\n",
      "9570\n",
      "9580\n",
      "9590\n",
      "9600\n",
      "9610\n",
      "9620\n",
      "9630\n",
      "9640\n",
      "9650\n",
      "9660\n",
      "9670\n",
      "9680\n",
      "9690\n",
      "9700\n",
      "9710\n",
      "9720\n",
      "9730\n",
      "9740\n",
      "9750\n",
      "9760\n",
      "9770\n",
      "9780\n",
      "9790\n",
      "9800\n",
      "9810\n",
      "9820\n",
      "9830\n",
      "9840\n",
      "9850\n",
      "9860\n",
      "9870\n",
      "9880\n",
      "9890\n",
      "9900\n",
      "9910\n",
      "9920\n",
      "9930\n",
      "9940\n",
      "9950\n",
      "9960\n",
      "9970\n",
      "9980\n",
      "9990\n",
      "10000\n",
      "10010\n",
      "10020\n",
      "10030\n",
      "10040\n",
      "10050\n",
      "10060\n",
      "10070\n",
      "10080\n",
      "10090\n",
      "10100\n",
      "10110\n",
      "10120\n",
      "10130\n",
      "10140\n",
      "10150\n",
      "10160\n",
      "10170\n",
      "10180\n",
      "10190\n",
      "10200\n",
      "10210\n",
      "10220\n",
      "10230\n",
      "10240\n",
      "10250\n",
      "10260\n",
      "10270\n",
      "10280\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(7000, 100000):\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print i + 1\n",
    "    obj_start = np.random.randint(0, num_positions)\n",
    "    obj = obj_start\n",
    "    \n",
    "    trajectory = []\n",
    "    states = []\n",
    "    actions = []\n",
    "        \n",
    "    # Generate a single trajectory\n",
    "    for j in xrange(10):\n",
    "        a = np.random.randint(0, num_actions)\n",
    "        while (obj == 0 and a == 0) or (obj == num_positions - 1 and a == 2):\n",
    "            a = np.random.randint(0, num_actions)\n",
    "        obj = obj - 1 if a == 0 else obj if a == 1 else obj + 1\n",
    "        trajectory.append(obj)\n",
    "        \n",
    "    prev_box = obj_start\n",
    "    j = 0\n",
    "        \n",
    "    # Feedforward for all steps in the trajectory\n",
    "    while j < len(trajectory):\n",
    "        current_state = np.zeros(num_positions + 1)\n",
    "        current_state[-1] = prev_box\n",
    "        current_state[trajectory[j]] = 1\n",
    "                \n",
    "        # Evaluate the Q-network to get the Q-values, and on the basis of that, select an action, and\n",
    "        # consequently calculate the current box coordinates from the action on the previous box coordinates\n",
    "        current_qvalues = feedforward(current_state, W)\n",
    "        current_action = epsilon_greedy(current_qvalues)\n",
    "        current_box = prev_box - 1 if current_action == 0 else prev_box if current_action == 1 else prev_box + 1\n",
    "                \n",
    "        # If the current box coordinates are invalid (out of bounds), we set a penalty for them and backpropagate.\n",
    "        # Otherwise, we add the new state and action to their respective arrays.\n",
    "        if current_box < 0 or current_box >= num_positions:\n",
    "            gradients = np.matrix(current_state).T * np.matrix([0 if current_action != x else 1 for x in xrange(num_actions)])\n",
    "            backpropagate(gradients)\n",
    "            j = 0\n",
    "            states = []\n",
    "            actions = []\n",
    "            prev_box = obj_start\n",
    "        else:\n",
    "            states.append(current_state)\n",
    "            actions.append(current_action)\n",
    "            prev_box = current_box\n",
    "            j += 1\n",
    "                \n",
    "    # We now have valid (not necessarily correct) results for the entire trajectory. We assign a reward +1 if\n",
    "    # the predicted final frame is the same as the ground truth, otherwise we assign a reward -1. To each\n",
    "    # intermediate step in the trajectory, we assign the reward 0.\n",
    "    reward = 1 if current_box == trajectory[-1] else -1\n",
    "    prev_box = obj_start\n",
    "    old_W = W\n",
    "    \n",
    "    for j in xrange(len(trajectory) - 2, -1, -1):\n",
    "        current_state = states[j]\n",
    "        current_action = actions[j]\n",
    "        prev_box = current_state[-1]\n",
    "        current_box = prev_box - 1 if current_action == 0 else prev_box if current_action == 1 else prev_box + 1\n",
    "        \n",
    "        current_qvalues = feedforward(current_state, old_W)\n",
    "        \n",
    "        next_state = current_state\n",
    "        next_state[-1] = current_box\n",
    "        \n",
    "        next_qvalues = feedforward(next_state, old_W)\n",
    "        \n",
    "        max_action = np.argmax(next_qvalues)\n",
    "                        \n",
    "        # We will only update weights for the max action chosen for the next state, so all other actions are made to\n",
    "        # have the same output as the previous output for Q-values so that their loss is 0 and thus not updated.\n",
    "        target_qvalues = np.array([(reward + gamma * next_qvalues[x]) if x == max_action else current_qvalues[x] for x in xrange(len(next_qvalues))])\n",
    "        \n",
    "        target_qvalues = np.matrix(target_qvalues)\n",
    "        current_qvalues = np.matrix(current_qvalues)\n",
    "        next_state = np.matrix(next_state)\n",
    "        current_state = np.matrix(current_state)\n",
    "        \n",
    "        # Obtaining gradient values and backpropagating\n",
    "        gradients = current_state.T * (target_qvalues - current_qvalues)\n",
    "        backpropagate(gradients)\n",
    "        \n",
    "        # Only the reward for the final step is +/- 1, and so, we set the reward to 0 for all intermediate steps.\n",
    "        reward = 0\n",
    "        \n",
    "    if (i + 1) % 1000 == 0:\n",
    "        np.save(str(i + 1) + '.npy', W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
