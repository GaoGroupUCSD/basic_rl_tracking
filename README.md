This repository contains codes dealing with tracking a ball moving either left or right, or staying at its position in a 1-D input space. 

Phase II deals with Q learning codes (the codes have comments that are understandable).

Phase III uses neural networks as function approximators for estimating the Q-values or the probabilities of the actions to be followed in the case of policy gradient, and actor critic methods.


